Title: Data integration big data performance using Elasticsearch - Blackcoffer Insights HomeOur Success StoriesData integration big data performance using ElasticsearchOur Success StoriesITData integration big data performance using ElasticsearchByAjay Bidyarthy-July 13, 20223135Client BackgroundClient:A Leading Tech Firm USAIndustry Type:IT & ConsultingServices:Software, Business Solutions, ConsultingOrganization Size:200+Project ObjectiveMigrate existing databases Postgres elastic search since Elasticserach performs better search operations. addition this, backend javascript also needed changed order query new elasticsearch database.Project DescriptionThe client’s website a visualization tool. also GUI add filters. make visualizations, least 50,000 records needed pulled Postgres database whose size would around 200mbs. would take a lot time (nearly 20-30 secs). Adding filters would take additional time. task move entire database Elasticsearch postgres since way faster search operations also filtering data. Since database changed, also write new backend code would query Elasticsearch database.Our SolutionSetup ELK stack (Elasticsearch, Logstash, Kibana) AWS EC2 instance.Write a pipeline file (.conf file) used ingest data postgres elasticsearch. datatypes cloumns, unique constraints, datetime formats etc., defined file. executed help logstash.Once data inserted, queried kibana’s built query compiler. check veracity data.Identify code backend needs changed.Replace code new code would query elasticserach. use elastic_query_builder module this.Testing Postgres Elasticsearch performance.Project DeliverablesSetup ELK stack (Elasticsearch, Logstash, Kibana) AWS EC2 instance.Pipeline i.e; logstash fileNew working backend code elasticsearchCommands check elastic data.Customizable logstash pipelineTools usedElasticsearchPostmanKibanaLogstashPythonJavascriptAmazon Web ServicesPostgresDockerGit BucketGithubLanguage/techniques usedJavascriptJsonDomain-Specific Language elasticsearchbashSkills usedElasticsearch query knowledgePostgres query knowledgeNetworkingJavascriptBackend web stackDatabases usedPostgresElasticsearchWeb Cloud Servers usedAmazon Web Services (AWS)What technical Challenges Faced Project ExecutionSometimes large responses elasticsearch ( size 500mb), time taken 30 secs.How Technical Challenges SolvedTo solve mentioned problem, used gzip request url’s header. significantly reduced execution times.Business ImpactEarlier postgres infrastructure took around 20-30 secs consistently less 10 secs perform filter search operations. would contribute a better user experience.Project SnapshotsPrevious articleWeb Data ConnectorNext articleAuvik, Connectwise integration GrafanaAjay BidyarthyRELATED ARTICLESMORE AUTHORAI ML-Based YouTube Analytics Content Creation Tool Optimizing Subscriber Engagement Content StrategyEnhancing Front-End Features Functionality Improved User Experience Dashboard Accuracy Partner Hospital ApplicationROAS Dashboard Campaign-Wise Google Ads Budget Tracking Using Google Ads APMOST POPULAR INSIGHTSETL PipelineOctober 6, 2019Traceability information – Master data capitalJune 13, 2019Impact Indian Economy due COVID-19April 12, 2020Future Work: Robot, AI AutomationJune 26, 2021Load moreRECOMMENDED INSIGHTSHow AI will impact future work?Integration a product a cloud-based CRM platformBig Data & Analytics Bring Transparency Good GovernanceRising Cities Impact Economy, Environment, Infrastructure,...