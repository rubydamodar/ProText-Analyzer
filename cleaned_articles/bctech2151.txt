Title: Stocktwits Data Structurization - Blackcoffer Insights HomeOur Success StoriesStocktwits Data StructurizationOur Success StoriesBanking, Financials, Securities, InsuranceStocktwits Data StructurizationByAjay Bidyarthy-August 30, 20213309Client BackgroundClient:A leading financial institution USAIndustry Type:Financial services & ConsultingServices:Financial consultantOrganization Size:100+Project Objective>To process two json file stocktwits_legacy_msg_2015_10.txt (file size = 2 GB) & stocktwits_legacy_msg_2015_10.txt (file size = 3.5 GB).>To handle Nested Json files conversion one merged Data Frame need perform Data Structurization.>While accessing a Json file JupyterNB, I need perform Chunking file size bigger json format avoid PC standstill.>After Data Preprocessing I need perform Exploratory Data Analysis Data.> Conditional Programming deal Data Transferring a particular folder based column values.Project DescriptionDuring training period I involved 2 live projects, One project named ‘Stocktwits Data Structurization’ I process huge JSON Data already obtained size data nearly 5 GB need process data chunking chunk size = 20000 rows a time. file nested JSON data within it’s attributes abstracts data nested columns a new dataframe. Completed handling complex nested json formed columns abstracted nested json. need Handle missing data mapping another index dataset missing values certain attributes handled mean value 0 substitution. task involves numerous pandas operations along multiple python functions. done Exploratory Data Analysis cleaned dataset finding correlation matrix plotting certain seaborn graphs strong correlated attributes.Our SolutionWorked Accessing Json Data, done tree Analysis Json Sample data.Both File big reading applying Python Code JupyterNb, performed chunking stocktwits_legacy_messages_2015_10.txt chunk size = 20000 rows a time. Similarly trying file.Created a list chunked files Json Data & Concat files list.The File Nested Json data within it’s attributes abstracted data nested columns a new DataFrame. Completed handling complex nested json formed columns abstracted nested json.Renamed columns identification. (Eg: ‘id’ ‘entities_id’) likewise others. merging data doesn’t create issue. Completed forming Preprocessed csv file 1st json file Output2015.csv.For Second file size > 3gb splitted file ten parts individually solved nested json parts like done 1st file finally concat one, handled columns arrangements removed unwanted columns finally removed dictionary representation entity_sentiments column. Completed forming Preprocessed csv file 2nd json file Output_Stocktwits_2017.csv.The cleaned dataset finding correlation matrix plotting certain seaborn graphs strong correlated attributes. done Exploratory Data Analysis cleaned dataset finding correlation matrix plotting certain seaborn graphs strong correlated attributes. Conditional Programming deal Data Transferring a particular folder based column values.Project DeliverablesCategorized Preprocessed CSV FilesPython ScriptiPython NB comments performed code.Tools used● Jupyter Notebook● Anaconda● Notepad++● Sublime Text● Brackets● JsonViewerLanguage/techniques used● Python ProgrammingModels usedMy project ‘Stocktwits Data Structurization’ developed a software model makes project high quality, reliable cost effective.● Software Model : RAD(Rapid Application Development model) Model● project follows a RAD Model model forming loop end start, also project based prototyping without specific planning. RAD model, less attention paid planning priority given development tasks. targets developing software a short span time.● Advantages RAD Model:o Changing requirements accommodated.o Progress measured.o Iteration time short use powerful RAD tools.o Productivity fewer people a short time.o Reduced development time.o Increases reusability components.o Quick initial reviews occur.o Encourages customer feedback.o Integration beginning solves a lot integration issuesSkills used● Data Mining● Data Wrangling● Data Visualization● Python Programming including OOPs Exception HandlingDatabases usedNo Databases used, data stored Google Drive Local Device.Web Cloud Servers usedNo Cloud Server usedWhat technical Challenges Faced Project Execution● Handling Huge Data Data Cleaning● JSON Data Serialization.● Solving Complex Nested JSON data provided.How Technical Challenges Solved● Handling Huge Data Data CleaningSolved Breaking Dataset 10 stream parts data huge able read easily Jupyter NB.● JSON Data SerializationSolved Data Chunking chunk_size=20000 means serialization data processing 20000 rows a time.● Solving Complex Nested JSON data provided.Viewed Structure part data JSON Viewer Changed data proper standard JSON Format. Reading JSON Data Performing Normalization Nested JSON data setting maximum level normalization specifying proper orient form. Normalization remaining Unsolved Nested JSON solved using Dictionary Conversions Structuring data.Project SnapshotsFigure 1 Sample Input Dataframe Converting Outer JSONFigure 2 Sample Output Dataframe Solving Nested JSON Data PreprocessingPrevious articleHow artificial intelligence boost productivity level?Next articleMarbles Stimulation using pythonAjay BidyarthyRELATED ARTICLESMORE AUTHORAI ML-Based YouTube Analytics Content Creation Tool Optimizing Subscriber Engagement Content StrategyEnhancing Front-End Features Functionality Improved User Experience Dashboard Accuracy Partner Hospital ApplicationROAS Dashboard Campaign-Wise Google Ads Budget Tracking Using Google Ads APMOST POPULAR INSIGHTSIntegration Python Power BI, Python External Tool...June 26, 2021Big Data solution online multivendor marketplace eCommerce businessJanuary 16, 2022Dynamic, Brand-Centric Dashboard Automotive Dealerships: PDF Financial Insights with...August 25, 2024Rise OTT platform impact entertainment industry by...October 17, 2022Load moreRECOMMENDED INSIGHTSData Management a Political SaaS ApplicationLessons past: key learnings relevant coronavirus...Business Analytics Textile Industry (Raymond Ltd.)The 8 Steps AI/ML Project