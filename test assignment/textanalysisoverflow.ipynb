{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "import syllapy\n",
    "import os\n",
    "output_directory = r'C:\\Users\\abhis\\Desktop\\projects task\\extracted_articles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = {}\n",
    "for filename in os.listdir(output_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        url_id = filename.split('.')[0]\n",
    "        with open(os.path.join(output_directory, filename), 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        articles[url_id] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abhis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\abhis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from textblob import TextBlob\n",
    "import syllapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text):\n",
    "    \"\"\"\n",
    "    Perform textual analysis on the given text and return various metrics.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to analyze.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing textual analysis metrics.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Tokenize sentences and words using spaCy\n",
    "    sentences = list(doc.sents)\n",
    "    words = [token.text for token in doc if token.is_alpha]\n",
    "    \n",
    "    # Count words and syllables\n",
    "    word_count = len(words)\n",
    "    syllable_count = sum(syllapy.count(word) for word in words)\n",
    "    avg_word_length = sum(len(word) for word in words) / word_count if word_count > 0 else 0\n",
    "    \n",
    "    # Calculate TextBlob scores\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "    \n",
    "    # Count complex words\n",
    "    stop_words = set(nlp.Defaults.stop_words)\n",
    "    complex_words = [word for word in words if len(word) > 2 and word.lower() not in stop_words]\n",
    "    complex_word_count = len(complex_words)\n",
    "    percentage_complex_words = (complex_word_count / word_count) * 100 if word_count > 0 else 0\n",
    "    \n",
    "    # Calculate Fog Index\n",
    "    avg_sentence_length = word_count / len(sentences) if len(sentences) > 0 else 0\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "    \n",
    "    # Count personal pronouns\n",
    "    personal_pronouns = [word for word in words if word.lower() in ['i', 'me', 'my', 'mine', 'we', 'our', 'ours', 'us']]\n",
    "    personal_pronoun_count = len(personal_pronouns)\n",
    "    \n",
    "    return {\n",
    "        'positive_score': max(polarity, 0),\n",
    "        'negative_score': min(polarity, 0),\n",
    "        'polarity_score': polarity,\n",
    "        'subjectivity_score': subjectivity,\n",
    "        'avg_sentence_length': avg_sentence_length,\n",
    "        'percentage_complex_words': percentage_complex_words,\n",
    "        'fog_index': fog_index,\n",
    "        'avg_words_per_sentence': word_count / len(sentences) if len(sentences) > 0 else 0,\n",
    "        'complex_word_count': complex_word_count,\n",
    "        'word_count': word_count,\n",
    "        'syllable_per_word': syllable_count / word_count if word_count > 0 else 0,\n",
    "        'personal_pronouns': personal_pronoun_count,\n",
    "        'avg_word_length': avg_word_length\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample articles dictionary with URL_IDs and their content\n",
    "articles = {\n",
    "    'bctech2073': \"\"\"\n",
    "    Title: Future of AI in Technology\n",
    "    The rise of artificial intelligence (AI) is transforming industries. AI's applications are vast, ranging from healthcare to finance. In healthcare, AI assists in diagnosing diseases early and predicting patient outcomes. In finance, it is used for fraud detection and algorithmic trading. The future of AI looks promising with advancements in machine learning and natural language processing. However, ethical considerations and data privacy concerns must be addressed to harness AI's full potential responsibly.\n",
    "    \"\"\",\n",
    "    \n",
    "    'bctech2074': \"\"\"\n",
    "    Title: The Impact of Climate Change on Coastal Cities\n",
    "    Coastal cities are facing increasing threats from climate change. Rising sea levels, caused by melting polar ice and thermal expansion of seawater, pose significant risks. Storm surges and flooding are becoming more frequent and severe, affecting infrastructure and communities. Mitigation strategies include constructing sea walls, improving drainage systems, and developing sustainable urban planning practices. The adaptation efforts are critical to minimize damage and ensure the resilience of coastal cities.\n",
    "    \"\"\",\n",
    "    \n",
    "    'bctech2075': \"\"\"\n",
    "    Title: Innovations in Renewable Energy\n",
    "    Renewable energy technologies are advancing rapidly, offering sustainable solutions to meet global energy demands. Solar power, wind energy, and hydroelectricity are leading the way. Innovations in photovoltaic cells, wind turbine designs, and energy storage systems are enhancing efficiency and reducing costs. The shift towards renewables is driven by the need to combat climate change and reduce reliance on fossil fuels. As technology evolves, the integration of renewables into energy grids will become more seamless and widespread.\n",
    "    \"\"\",\n",
    "    \n",
    "    'bctech2076': \"\"\"\n",
    "    Title: Trends in Modern Education Technology\n",
    "    Education technology is evolving with the integration of digital tools and platforms. Online learning, interactive simulations, and virtual classrooms are becoming common. These technologies offer personalized learning experiences and access to a global knowledge base. The use of artificial intelligence and data analytics in education helps track student progress and tailor educational content. While technology enhances learning opportunities, challenges such as digital divide and data security must be addressed.\n",
    "    \"\"\",\n",
    "    \n",
    "    'bctech2077': \"\"\"\n",
    "    Title: The Role of Big Data in Business Strategy\n",
    "    Big data analytics is revolutionizing business strategies by providing actionable insights from vast amounts of data. Companies use big data to understand consumer behavior, optimize operations, and drive innovation. Advanced analytics tools help in predictive modeling and decision-making processes. The effective use of big data requires robust data management practices and skilled professionals to interpret complex datasets. Leveraging big data can lead to competitive advantages and improved business outcomes.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# This dictionary contains sample articles with URL_IDs and corresponding content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for url_id, content in articles.items():\n",
    "    analysis = analyze_text(content)\n",
    "    results.append({'URL_ID': url_id, **analysis})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>percentage_complex_words</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>avg_words_per_sentence</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>syllable_per_word</th>\n",
       "      <th>personal_pronouns</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bctech2073</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.559091</td>\n",
       "      <td>13.0</td>\n",
       "      <td>56.410256</td>\n",
       "      <td>27.764103</td>\n",
       "      <td>13.0</td>\n",
       "      <td>44</td>\n",
       "      <td>78</td>\n",
       "      <td>1.897436</td>\n",
       "      <td>0</td>\n",
       "      <td>5.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bctech2074</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>0.510714</td>\n",
       "      <td>15.6</td>\n",
       "      <td>73.076923</td>\n",
       "      <td>35.470769</td>\n",
       "      <td>15.6</td>\n",
       "      <td>57</td>\n",
       "      <td>78</td>\n",
       "      <td>1.935897</td>\n",
       "      <td>0</td>\n",
       "      <td>6.141026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bctech2075</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>16.2</td>\n",
       "      <td>67.901235</td>\n",
       "      <td>33.640494</td>\n",
       "      <td>16.2</td>\n",
       "      <td>55</td>\n",
       "      <td>81</td>\n",
       "      <td>2.074074</td>\n",
       "      <td>0</td>\n",
       "      <td>5.975309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bctech2076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>51</td>\n",
       "      <td>75</td>\n",
       "      <td>2.226667</td>\n",
       "      <td>0</td>\n",
       "      <td>6.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bctech2077</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>15.8</td>\n",
       "      <td>77.215190</td>\n",
       "      <td>37.206076</td>\n",
       "      <td>15.8</td>\n",
       "      <td>61</td>\n",
       "      <td>79</td>\n",
       "      <td>2.113924</td>\n",
       "      <td>0</td>\n",
       "      <td>6.063291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       URL_ID  positive_score  negative_score  polarity_score  \\\n",
       "0  bctech2073        0.050000            0.00        0.050000   \n",
       "1  bctech2074        0.191667            0.00        0.191667   \n",
       "2  bctech2075        0.200000            0.00        0.200000   \n",
       "3  bctech2076        0.000000           -0.08       -0.080000   \n",
       "4  bctech2077        0.120000            0.00        0.120000   \n",
       "\n",
       "   subjectivity_score  avg_sentence_length  percentage_complex_words  \\\n",
       "0            0.559091                 13.0                 56.410256   \n",
       "1            0.510714                 15.6                 73.076923   \n",
       "2            0.200000                 16.2                 67.901235   \n",
       "3            0.440000                 15.0                 68.000000   \n",
       "4            0.380000                 15.8                 77.215190   \n",
       "\n",
       "   fog_index  avg_words_per_sentence  complex_word_count  word_count  \\\n",
       "0  27.764103                    13.0                  44          78   \n",
       "1  35.470769                    15.6                  57          78   \n",
       "2  33.640494                    16.2                  55          81   \n",
       "3  33.200000                    15.0                  51          75   \n",
       "4  37.206076                    15.8                  61          79   \n",
       "\n",
       "   syllable_per_word  personal_pronouns  avg_word_length  \n",
       "0           1.897436                  0         5.794872  \n",
       "1           1.935897                  0         6.141026  \n",
       "2           2.074074                  0         5.975309  \n",
       "3           2.226667                  0         6.400000  \n",
       "4           2.113924                  0         6.063291  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = r'C:\\Users\\abhis\\Desktop\\projects task\\analysis_results.csv'\n",
    "excel_file_path = r'C:\\Users\\abhis\\Desktop\\projects task\\analysis_results.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(csv_file_path, index=False)\n",
    "results_df.to_excel(excel_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C:/Users/abhis/Desktop/projects task/extracted_articles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = {}\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            articles[filename] = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for url_id, content in articles.items():\n",
    "    analysis = analyze_text(content)\n",
    "    results.append({'URL_ID': url_id, **analysis})\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>percentage_complex_words</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>avg_words_per_sentence</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>syllable_per_word</th>\n",
       "      <th>personal_pronouns</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bctech2011.txt</td>\n",
       "      <td>0.083778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083778</td>\n",
       "      <td>0.393588</td>\n",
       "      <td>18.985507</td>\n",
       "      <td>69.694656</td>\n",
       "      <td>35.472065</td>\n",
       "      <td>18.985507</td>\n",
       "      <td>1826</td>\n",
       "      <td>2620</td>\n",
       "      <td>2.162214</td>\n",
       "      <td>3</td>\n",
       "      <td>6.327099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bctech2012.txt</td>\n",
       "      <td>0.141558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141558</td>\n",
       "      <td>0.377201</td>\n",
       "      <td>11.836735</td>\n",
       "      <td>74.655172</td>\n",
       "      <td>34.596763</td>\n",
       "      <td>11.836735</td>\n",
       "      <td>433</td>\n",
       "      <td>580</td>\n",
       "      <td>2.410345</td>\n",
       "      <td>1</td>\n",
       "      <td>7.158621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bctech2013.txt</td>\n",
       "      <td>0.142706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142706</td>\n",
       "      <td>0.458439</td>\n",
       "      <td>16.363636</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>36.545455</td>\n",
       "      <td>16.363636</td>\n",
       "      <td>540</td>\n",
       "      <td>720</td>\n",
       "      <td>2.248611</td>\n",
       "      <td>2</td>\n",
       "      <td>6.656944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bctech2014.txt</td>\n",
       "      <td>0.082168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082168</td>\n",
       "      <td>0.255944</td>\n",
       "      <td>10.448276</td>\n",
       "      <td>76.897690</td>\n",
       "      <td>34.938386</td>\n",
       "      <td>10.448276</td>\n",
       "      <td>466</td>\n",
       "      <td>606</td>\n",
       "      <td>2.377888</td>\n",
       "      <td>2</td>\n",
       "      <td>6.986799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bctech2015.txt</td>\n",
       "      <td>0.101338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101338</td>\n",
       "      <td>0.391190</td>\n",
       "      <td>21.343750</td>\n",
       "      <td>65.446559</td>\n",
       "      <td>34.716124</td>\n",
       "      <td>21.343750</td>\n",
       "      <td>447</td>\n",
       "      <td>683</td>\n",
       "      <td>2.156662</td>\n",
       "      <td>2</td>\n",
       "      <td>6.439239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>bctech2153.txt</td>\n",
       "      <td>0.084077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084077</td>\n",
       "      <td>0.389070</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>66.452991</td>\n",
       "      <td>40.981197</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>622</td>\n",
       "      <td>936</td>\n",
       "      <td>2.057692</td>\n",
       "      <td>4</td>\n",
       "      <td>5.947650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>bctech2154.txt</td>\n",
       "      <td>0.058422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058422</td>\n",
       "      <td>0.253377</td>\n",
       "      <td>23.672131</td>\n",
       "      <td>62.257618</td>\n",
       "      <td>34.371900</td>\n",
       "      <td>23.672131</td>\n",
       "      <td>899</td>\n",
       "      <td>1444</td>\n",
       "      <td>1.851801</td>\n",
       "      <td>10</td>\n",
       "      <td>5.439058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>bctech2155.txt</td>\n",
       "      <td>0.080068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080068</td>\n",
       "      <td>0.328829</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>58.433735</td>\n",
       "      <td>34.440161</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>291</td>\n",
       "      <td>498</td>\n",
       "      <td>1.887550</td>\n",
       "      <td>15</td>\n",
       "      <td>5.652610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>bctech2156.txt</td>\n",
       "      <td>0.030114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030114</td>\n",
       "      <td>0.440909</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>82.352941</td>\n",
       "      <td>58.441176</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>210</td>\n",
       "      <td>255</td>\n",
       "      <td>2.329412</td>\n",
       "      <td>0</td>\n",
       "      <td>6.878431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>bctech2157.txt</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.255519</td>\n",
       "      <td>22.833333</td>\n",
       "      <td>65.328467</td>\n",
       "      <td>35.264720</td>\n",
       "      <td>22.833333</td>\n",
       "      <td>179</td>\n",
       "      <td>274</td>\n",
       "      <td>2.025547</td>\n",
       "      <td>2</td>\n",
       "      <td>6.058394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID  positive_score  negative_score  polarity_score  \\\n",
       "0    bctech2011.txt        0.083778             0.0        0.083778   \n",
       "1    bctech2012.txt        0.141558             0.0        0.141558   \n",
       "2    bctech2013.txt        0.142706             0.0        0.142706   \n",
       "3    bctech2014.txt        0.082168             0.0        0.082168   \n",
       "4    bctech2015.txt        0.101338             0.0        0.101338   \n",
       "..              ...             ...             ...             ...   \n",
       "142  bctech2153.txt        0.084077             0.0        0.084077   \n",
       "143  bctech2154.txt        0.058422             0.0        0.058422   \n",
       "144  bctech2155.txt        0.080068             0.0        0.080068   \n",
       "145  bctech2156.txt        0.030114             0.0        0.030114   \n",
       "146  bctech2157.txt        0.128571             0.0        0.128571   \n",
       "\n",
       "     subjectivity_score  avg_sentence_length  percentage_complex_words  \\\n",
       "0              0.393588            18.985507                 69.694656   \n",
       "1              0.377201            11.836735                 74.655172   \n",
       "2              0.458439            16.363636                 75.000000   \n",
       "3              0.255944            10.448276                 76.897690   \n",
       "4              0.391190            21.343750                 65.446559   \n",
       "..                  ...                  ...                       ...   \n",
       "142            0.389070            36.000000                 66.452991   \n",
       "143            0.253377            23.672131                 62.257618   \n",
       "144            0.328829            27.666667                 58.433735   \n",
       "145            0.440909            63.750000                 82.352941   \n",
       "146            0.255519            22.833333                 65.328467   \n",
       "\n",
       "     fog_index  avg_words_per_sentence  complex_word_count  word_count  \\\n",
       "0    35.472065               18.985507                1826        2620   \n",
       "1    34.596763               11.836735                 433         580   \n",
       "2    36.545455               16.363636                 540         720   \n",
       "3    34.938386               10.448276                 466         606   \n",
       "4    34.716124               21.343750                 447         683   \n",
       "..         ...                     ...                 ...         ...   \n",
       "142  40.981197               36.000000                 622         936   \n",
       "143  34.371900               23.672131                 899        1444   \n",
       "144  34.440161               27.666667                 291         498   \n",
       "145  58.441176               63.750000                 210         255   \n",
       "146  35.264720               22.833333                 179         274   \n",
       "\n",
       "     syllable_per_word  personal_pronouns  avg_word_length  \n",
       "0             2.162214                  3         6.327099  \n",
       "1             2.410345                  1         7.158621  \n",
       "2             2.248611                  2         6.656944  \n",
       "3             2.377888                  2         6.986799  \n",
       "4             2.156662                  2         6.439239  \n",
       "..                 ...                ...              ...  \n",
       "142           2.057692                  4         5.947650  \n",
       "143           1.851801                 10         5.439058  \n",
       "144           1.887550                 15         5.652610  \n",
       "145           2.329412                  0         6.878431  \n",
       "146           2.025547                  2         6.058394  \n",
       "\n",
       "[147 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'C:/Users/abhis/Desktop/projects task/textual_analysis_results.xlsx'\n",
    "results_df.to_excel(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
