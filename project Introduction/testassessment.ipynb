{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Task Structure Explanation\n",
    "\n",
    "## üóÇ Directories and Files\n",
    "\n",
    "### üìù Cleaned Articles\n",
    "- **`cleaned_articles`**: Contains the articles that have been cleaned and are ready for analysis. This directory includes text files with preprocessed content.\n",
    "\n",
    "### üìÇ Extracted Articles\n",
    "- **`extracted_articles`**: Holds the raw articles that were initially extracted for the project. This directory is used as the source for further processing and analysis.\n",
    "\n",
    "### üìö Master Dictionary\n",
    "- **`master dictionary`**: A collection of files used for sentiment analysis and text processing.\n",
    "  - **`cleaned negative words.txt`**: Contains a list of negative words after cleaning.\n",
    "  - **`cleaned positive words.txt`**: Contains a list of positive words after cleaning.\n",
    "  - **`negative-words.txt`**: Raw file with negative words for sentiment analysis.\n",
    "  - **`positive-words.txt`**: Raw file with positive words for sentiment analysis.\n",
    "\n",
    "### üìë Project Introduction\n",
    "- **`project Introduction`**: Provides an overview and objectives of the project. Includes introductory material and project goals.\n",
    "\n",
    "### üß™ Test Assessment\n",
    "- **`test assessment`**: Contains test assignments and notebooks related to the assessment.\n",
    "  - **`dataextraction.ipynb`**: Jupyter Notebook for data extraction tasks.\n",
    "  - **`testassessment.ipynb`**: Jupyter Notebook for additional test assessments.\n",
    "\n",
    "### üíª Code and Markdown\n",
    "- **`testassignment`**: Includes code and markdown files related to test assignments.\n",
    "  - **`Code + Markdown |`**: Contains code snippets and markdown explanations for the test assignments.\n",
    "  - **`Run All`**: A script or command to execute all code cells in notebooks.\n",
    "\n",
    "### üö´ Stop Words\n",
    "- **`Stop Words`**: Directory containing various stop words files used to clean and preprocess text.\n",
    "  - **`StopWords Auditor.txt`**: Stop words used for auditing and review.\n",
    "  - **`StopWords Currencies.txt`**: Stop words related to currency names and symbols.\n",
    "  - **`StopWords Datasand Numbers.txt`**: Stop words related to data and numbers.\n",
    "  - **`StopWords Generic.txt`**: General stop words list.\n",
    "  - **`StopWords GenericLong.txt`**: Extended list of generic stop words.\n",
    "  - **`StopWords Geographic.txt`**: Stop words related to geographic locations.\n",
    "  - **`StopWords Names.txt`**: Stop words related to personal names.\n",
    "\n",
    "### üìä Text Analysis\n",
    "- **`Text Analysis`**: Contains various files and notebooks for performing text analysis.\n",
    "  - **`textanalysis.ipynb`**: Jupyter Notebook for conducting text analysis.\n",
    "  - **`textanalysisoverflow.ipynb`**: Additional notebook for overflow analysis tasks.\n",
    "  - **`sentiment analysis.log`**: Log file recording the results of sentiment analysis.\n",
    "  - **`textblob sentiment result.csv`**: CSV file with sentiment analysis results using TextBlob.\n",
    "  - **`textual analysis metrics.xlsx`**: Excel file with metrics from textual analysis.\n",
    "  - **`average word length.csv`**: CSV file containing results for average word length analysis.\n",
    "  - **`average word_per_sentence_results.csv`**: CSV file with results for average words per sentence.\n",
    "  - **`personal pronouns count.csv`**: CSV file with counts of personal pronouns found in the text.\n",
    "  - **`readability analysis results.csv`**: CSV file with readability analysis results.\n",
    "  - **`syllable count result.csv`**: CSV file with results for syllable counting in words.\n",
    "  - **`word count result.csv`**: CSV file with word count results.\n",
    "  - **`word frequency visualization.png`**: PNG file with a visualization of word frequency.\n",
    "  - **`Text Analysis.docx`**: Word document summarizing text analysis results.\n",
    "  - **`textual analysis results.docx`**: Word document with detailed results from textual analysis.\n",
    "  - **`sentiment analysis results.csv`**: CSV file with comprehensive sentiment analysis results.\n",
    "\n",
    "### üìà Additional Files\n",
    "- **`analysis results.csv`**: CSV file with various analysis results.\n",
    "- **`analysis results.xlsx`**: Excel file with summarized analysis results.\n",
    "- **`Objective.docx`**: Document outlining the objectives and goals of the project.\n",
    "- **`Output Data Structure.xlsx`**: Excel file describing the structure of the output data.\n",
    "- **`final text analysis results.xlsx`**: Final Excel file with all text analysis results compiled.\n",
    "\n",
    "## üìå Notes\n",
    "- Ensure all files are properly saved and backed up to avoid data loss.\n",
    "- Maintain consistency in file naming and formats to facilitate easier navigation and data management.\n",
    "- Verify that all analysis results are correctly generated and logged for accurate reporting and future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blackcoffer Test Assignment\n",
    "\n",
    "## üåê Company Information\n",
    "- **Consulting Website**: [Blackcoffer](https://blackcoffer.com) | [LSA Lead](https://lsalead.com/)\n",
    "- **Web App Products**: [Netclan](https://netclan.com/) | [Insights](https://insights.blackcoffer.com/) | [Hire Kingdom](https://hirekingdom.com/) | [Workcroft](https://workcroft.com/)\n",
    "- **Mobile App Products**: Netclan | Bwstory\n",
    "\n",
    "## üìã Assignment Overview\n",
    "\n",
    "### 1. Objective\n",
    "Extract textual data from the provided URLs and perform text analysis to compute specified variables.\n",
    "\n",
    "### 2. Data Extraction\n",
    "- **File**: `Input.xlsx`\n",
    "- **Task**: Extract the article title and text from each URL in `Input.xlsx`. Save the extracted content as text files named by `URL_ID`.\n",
    "- **Tools**: Use Python with libraries such as BeautifulSoup, Selenium, or Scrapy.\n",
    "\n",
    "### 3. Data Analysis\n",
    "- **File**: `Output Data Structure.xlsx`\n",
    "- **Task**: Perform textual analysis on the extracted articles and compute the required variables.\n",
    "- **Tools**: Python programming for data analysis.\n",
    "\n",
    "### 4. Variables\n",
    "Refer to `Text Analysis.docx` for definitions. Compute the following:\n",
    "1. Positive Score\n",
    "2. Negative Score\n",
    "3. Polarity Score\n",
    "4. Subjectivity Score\n",
    "5. Avg Sentence Length\n",
    "6. Percentage of Complex Words\n",
    "7. Fog Index\n",
    "8. Avg Number of Words Per Sentence\n",
    "9. Complex Word Count\n",
    "10. Word Count\n",
    "11. Syllable Per Word\n",
    "12. Personal Pronouns\n",
    "13. Avg Word Length\n",
    "\n",
    "### 5. Output Data Structure\n",
    "- **Include**:\n",
    "  - All input variables from `Input.xlsx`\n",
    "  - Computed variables: Positive Score, Negative Score, Polarity Score, Subjectivity Score, Avg Sentence Length, Percentage of Complex Words, Fog Index, Avg Number of Words Per Sentence, Complex Word Count, Word Count, Syllable Per Word, Personal Pronouns, Avg Word Length\n",
    "- **File Format**: CSV or Excel, following the format in `Output Data Structure.xlsx`.\n",
    "\n",
    "### 6. Timeline\n",
    "- **Duration**: 6 days (sooner is better).\n",
    "\n",
    "### 7. Submission\n",
    "- **Submit via**: [Google Form](https://forms.gle/nvWAgrCBdq1JkKou8)\n",
    "- **Requirements**:\n",
    "  - `.py` file\n",
    "  - Output in CSV or Excel\n",
    "  - Instructions documentation:\n",
    "    1. Approach explanation\n",
    "    2. How to run the `.py` file\n",
    "    3. List of dependencies required\n",
    "\n",
    "**Note**: Do not include any other files.\n",
    "\n",
    "---\n",
    "\n",
    "Good luck with your assignment!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis\n",
    "\n",
    "## Objective\n",
    "The objective of this document is to explain the methodology adopted for performing text analysis to derive sentimental opinions, sentiment scores, readability, passive words, personal pronouns, and other metrics.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Sentimental Analysis](#sentimental-analysis) - 2\n",
    "    1.1. [Cleaning using Stop Words Lists](#cleaning-using-stop-words-lists) - 2\n",
    "    1.2. [Creating Dictionary of Positive and Negative Words](#creating-dictionary-of-positive-and-negative-words) - 2\n",
    "    1.3. [Extracting Derived Variables](#extracting-derived-variables) - 2\n",
    "2. [Analysis of Readability](#analysis-of-readability) - 3\n",
    "3. [Average Number of Words Per Sentence](#average-number-of-words-per-sentence) - 3\n",
    "4. [Complex Word Count](#complex-word-count) - 3\n",
    "5. [Word Count](#word-count) - 3\n",
    "6. [Syllable Count Per Word](#syllable-count-per-word) - 4\n",
    "7. [Personal Pronouns](#personal-pronouns) - 4\n",
    "8. [Average Word Length](#average-word-length) - 4\n",
    "\n",
    "## 1. Sentimental Analysis\n",
    "Sentimental analysis involves determining whether a piece of writing is positive, negative, or neutral. The following algorithm is designed for use in Financial Texts:\n",
    "\n",
    "### 1.1. Cleaning using Stop Words Lists\n",
    "- **Purpose**: To clean the text so that Sentiment Analysis can be performed by excluding the words found in the Stop Words List.\n",
    "- **Source**: Stop Words Lists (located in the `StopWords` folder).\n",
    "\n",
    "### 1.2. Creating Dictionary of Positive and Negative Words\n",
    "- **Purpose**: To create a dictionary of Positive and Negative words.\n",
    "- **Source**: Master Dictionary (located in the `MasterDictionary` folder).\n",
    "- **Process**: Add words to the dictionary only if they are not found in the Stop Words Lists.\n",
    "\n",
    "### 1.3. Extracting Derived Variables\n",
    "Convert the text into a list of tokens using the NLTK tokenize module and calculate the following variables:\n",
    "- **Positive Score**: Assign a value of +1 for each word found in the Positive Dictionary and sum all values.\n",
    "- **Negative Score**: Assign a value of -1 for each word found in the Negative Dictionary, then sum all values and multiply by -1 to get a positive number.\n",
    "- **Polarity Score**: Determines if the text is positive or negative:\n",
    "  \\[\n",
    "  \\text{Polarity Score} = \\frac{\\text{Positive Score} - \\text{Negative Score}}{\\text{Positive Score} + \\text{Negative Score} + 0.000001}\n",
    "  \\]\n",
    "  Range: -1 to +1\n",
    "- **Subjectivity Score**: Determines if the text is objective or subjective:\n",
    "  \\[\n",
    "  \\text{Subjectivity Score} = \\frac{\\text{Positive Score} + \\text{Negative Score}}{\\text{Total Words after cleaning} + 0.000001}\n",
    "  \\]\n",
    "  Range: 0 to +1\n",
    "\n",
    "## 2. Analysis of Readability\n",
    "Readability is calculated using the Gunning Fox Index formula:\n",
    "- **Average Sentence Length**: Number of words / Number of sentences\n",
    "- **Percentage of Complex Words**: Number of complex words / Number of words\n",
    "- **Fog Index**:\n",
    "  \\[\n",
    "  \\text{Fog Index} = 0.4 \\times (\\text{Average Sentence Length} + \\text{Percentage of Complex Words})\n",
    "  \\]\n",
    "\n",
    "## 3. Average Number of Words Per Sentence\n",
    "Calculated as:\n",
    "\\[\n",
    "\\text{Average Number of Words Per Sentence} = \\frac{\\text{Total Number of Words}}{\\text{Total Number of Sentences}}\n",
    "\\]\n",
    "\n",
    "## 4. Complex Word Count\n",
    "- **Definition**: Words with more than two syllables.\n",
    "\n",
    "## 5. Word Count\n",
    "- **Process**:\n",
    "  1. Remove stop words (using the `stopwords` class of the NLTK package).\n",
    "  2. Remove punctuations like `?`, `!`, `,`, `.` before counting.\n",
    "\n",
    "## 6. Syllable Count Per Word\n",
    "- **Method**: Count the number of syllables in each word by counting the vowels. Handle exceptions such as words ending with \"es\" or \"ed\".\n",
    "\n",
    "## 7. Personal Pronouns\n",
    "- **Process**: Use regex to count occurrences of the words ‚ÄúI,‚Äù ‚Äúwe,‚Äù ‚Äúmy,‚Äù ‚Äúours,‚Äù and ‚Äúus.‚Äù Ensure that \"US\" as a country name is not included.\n",
    "\n",
    "## 8. Average Word Length\n",
    "- **Formula**:\n",
    "  \\[\n",
    "  \\text{Average Word Length} = \\frac{\\text{Sum of the Total Number of Characters in Each Word}}{\\text{Total Number of Words}}\n",
    "  \\]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
